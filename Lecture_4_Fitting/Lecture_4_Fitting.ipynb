{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Labs/Lectures\n",
    "\n",
    "## Lecture 4: Fitting\n",
    "Nicholas Lee-Hone\n",
    "\n",
    "July 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We will be using the `curve_fit` function from `scipy.optimize` in this lecture to do nonlinear least squares fitting. Internally `curve_fit` uses the Levenberg-Marquardt algorithm to perform the optimization.\n",
    "\n",
    "The following link provides more information on how the Levenberg-Marquardt algorithm works:\n",
    "- http://www.brnt.eu/phd/node10.html#SECTION00622700000000000000\n",
    "\n",
    "There is a much more sophisticated package called `lmfit` that allows for constraints between parameters, custom residual functions, and that automatically returns much more information about the fit such as the errors on the parameters and chisqr. Despite being a better package, it is more complex to set up and would probably be less suitable for a teaching environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting procedure\n",
    "- Load the data and plot it\n",
    "- Define the model function\n",
    "- Plot the model function on top of the data\n",
    "    - Explore model parameters until the model is close to the data\n",
    "- Run the fit algorithm and plot the results\n",
    "- Interpret the results of the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load the data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# Numpy for loading data and creating arrays\n",
    "import numpy as np\n",
    "# Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Alias scipy as sp\n",
    "import scipy as sp\n",
    "# scipy.optimize for the curve_fit function\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Despite the data having uncertainties we will start by fitting to the data as if it does not have any uncertainty. We will then explore what changes when the uncertainties are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv file. There is a header in the first line so skip it\n",
    "x_data, y_data, y_err = np.genfromtxt('Example-Data.csv', delimiter=',', unpack=True, skip_header=1)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_data, y_data, 'o')\n",
    "plt.xlim(xmin=0)\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model function always takes the independent variable as its first parameter, \n",
    "# and the parameters that will be optimized come after.\n",
    "def model(x, m, b):\n",
    "    return m*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot the model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points at which we will evaluate the model function\n",
    "x = np.linspace(0, max(x_data), 100)\n",
    "\n",
    "# Choose some initial guesses for the parameters\n",
    "m_init = 2.2\n",
    "b_init = 0\n",
    "\n",
    "plt.plot(x_data, y_data, 'o')\n",
    "# Plot the model using the initial parameter guesses\n",
    "plt.plot(x, model(x, m_init, b_init))\n",
    "plt.xlim(xmin=0)\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the fitting procedure and plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "`curve_fit` returns a tuple of values: pOpt, and pCov.\n",
    "\n",
    "pOpt is an array containing the optimized parameter values.\n",
    "\n",
    "pCov is the covariance matrix of pOpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pOpt1, pCov1 = sp.optimize.curve_fit(model, x_data, y_data, p0=(m_init, b_init))\n",
    "\n",
    "plt.plot(x_data, y_data, 'o')\n",
    "plt.plot(x, model(x, pOpt1[0], pOpt1[1]))\n",
    "plt.xlim(xmin=0)\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pOpt1, pCov1 = sp.optimize.curve_fit(model, x_data, y_data, p0=(m_init, b_init))\n",
    "\n",
    "plt.plot(x_data, y_data, 'o')\n",
    "plt.plot(x, model(x, *pOpt1))  # Use parameter expansion to fill the correct places\n",
    "plt.xlim(xmin=0)\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpret the fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertainty in a parameter $a_j$ is $\\alpha_j=\\sqrt{C_{jj}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape is used make the errors into a 1xN array to help build the correlation matrix\n",
    "errs1 = np.sqrt(pCov1.diagonal()).reshape((1, -1))\n",
    "errs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The correlation between two parameters is $$\\rho_{ij}=\\frac{C_{ij}}{\\sqrt{C_{ii}C_{jj}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr1 = pCov1/(errs1.T@errs1)\n",
    "corr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the correlation matrix as an image. For two parameters this is overkill, but it can be useful if you have many parameters in the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Set the range of values to be between -1 and 1 with vmin and vmax\n",
    "# Use a divergent colour map to represent the values. \n",
    "# 'RdBu' is a red to blue divergent color map. \n",
    "# Putting '_r' at the end reverses the color map order so it goes from blue to red instead.\n",
    "plt.imshow(corr1, vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.yticks([0, 1])\n",
    "plt.xticks([0, 1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Including uncertainties in the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first step in including the uncertainties is to set `sigma=y_err`. This assigs a weight $w_i=\\frac{1}{\\sigma_i^2}$ to residual $r_i$ in the nonlinear least squares fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute_sigma=False by default\n",
    "pOpt2, pCov2 = sp.optimize.curve_fit(model, x_data, y_data, p0=(m_init, b_init), sigma=y_err)\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='o', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt1), label='No uncertainties')\n",
    "plt.plot(x, model(x, *pOpt2), label='With uncertainties')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "errs2 = np.sqrt(pCov2.diagonal()).reshape((1, -1))\n",
    "errs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = pCov2/(errs2.T@errs2)\n",
    "corr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corr2, vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the previous iteration of the `curve_fit` the parameter `absolute_sigma` was set to `False` by default. This means that the sigma values are scaled so that the reduced chi^2 for the optimized fit parameters is 1. This would be used when we don't know the exact value of the uncertainty, but know the relative weights assigned to each point.\n",
    "\n",
    "In order to tell curve_fit that it should consider the scale of the uncertainties to be known we have to set `absolute_sigma=True` in the `curve_fit` parameters. The values of sigma are then not scaled, and the reduced chi^2 is not forced to be 1. This would be used when we know the actual uncertainty, as is typically the case in physics experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Set absolute_sigma=True to specify measured uncertainties\n",
    "pOpt3, pCov3 = sp.optimize.curve_fit(model, x_data, y_data, p0=(m_init, b_init), sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='o', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt2), label='absolute sigma=False')\n",
    "plt.plot(x, model(x, *pOpt3), label='absolute sigma=True')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "errs3 = np.sqrt(pCov3.diagonal()).reshape((1, -1))\n",
    "errs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr3 = pCov3/(errs3.T@errs3)\n",
    "corr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corr3, vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Add a scale parameter so we can rescale the uncertainties\n",
    "scale = 1\n",
    "\n",
    "# Fit with absolute_sigma=False\n",
    "pOpt2, pCov2 = sp.optimize.curve_fit(model, x_data, y_data, \n",
    "                                     p0=(m_init, b_init), sigma=y_err*scale)\n",
    "\n",
    "# Fit with absolute_sigma=True\n",
    "pOpt3, pCov3 = sp.optimize.curve_fit(model, x_data, y_data, \n",
    "                                     p0=(m_init, b_init), sigma=y_err*scale, \n",
    "                                     absolute_sigma=True)\n",
    "\n",
    "errs2 = np.sqrt(pCov2.diagonal()).reshape((1, -1))\n",
    "errs3 = np.sqrt(pCov3.diagonal()).reshape((1, -1))\n",
    "\n",
    "print('absolute_sigma=False:', errs2)\n",
    "print()\n",
    "print('absolute_sigma=True:', errs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importance of choosing initial parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Although algorithms like gradient descent and Levenberg-Marquardt are commonly referred to as fitting algorithms, this is a bit of a misnomer. These algorithms do not in fact fit to the data; they simply take an initial guess of the optimal parameters, and find some local minimum that is in some way reachable from this point.\n",
    "\n",
    "A more apt name for fitting algorithms would be refinement algorithms, as they refine some initial guess that is close to the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot the data\n",
    "# There are no uncertainties in the data, so we will assume the uncertainty is sqrt(y)\n",
    "x_data, y_data = np.genfromtxt('Gauss1.csv', delimiter=',', unpack=True)\n",
    "y_err = y_data**0.5\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "\n",
    "# Comment the previous errorbar command and uncomment this one if you want to see every third point\n",
    "#plt.errorbar(x_data[::3], y_data[::3], yerr=y_err[::3], fmt='.', capsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def model(x, B, tau, A1, mu1, sigma1, A2, mu2, sigma2):\n",
    "    # Exponential decay and two gaussian peaks\n",
    "    return B*np.exp(-x/tau) + A1*np.exp(-(x - mu1)**2/(2*sigma1**2)) + A2*np.exp(-(x - mu2)**2/(2*sigma2**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(x_data), max(x_data), 100)\n",
    "\n",
    "#   model(x,  B,  tau, A1, mu1, sigma1, A2, mu2, sigma2)  # Reminder of parameter order\n",
    "y = model(x,  1,   1,  1,   1,     1,   1,   1,   1)  # Bad initial parameter estimate\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, y, zorder=10, c='k') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pOpt, pCov = sp.optimize.curve_fit(model, x_data, y_data, p0=(1, 1, 1, 1, 1, 1, 1, 1),\n",
    "                                  sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt), zorder=10, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(x_data), max(x_data), 100)\n",
    "\n",
    "#   model(x,  B,  tau, A1, mu1, sigma1, A2, mu2, sigma2)  # Reminder of parameter order\n",
    "y = model(x, 100, 100, 50,  50,   20,   50, 90,   10)  # Bad initial parameter estimate\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, y, zorder=10, c='k') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pOpt, pCov = sp.optimize.curve_fit(model, x_data, y_data, p0=(100, 100, 50, 50, 20, 50, 90, 10),\n",
    "                                   sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt), c='k', zorder=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(x_data), max(x_data), 100)\n",
    "\n",
    "#   model(x,  B,  tau, A1, mu1, sigma1, A2, mu2, sigma2)  # Reminder of parameter order\n",
    "y = model(x, 100, 100, 50,  70,   20,   50, 180,   10)  # OK initial parameter estimate\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, y, zorder=10, c='k') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pOpt, pCov = sp.optimize.curve_fit(model, x_data, y_data, p0=(100, 100, 50, 70, 20, 50, 180, 10),\n",
    "                                  sigma=y_err, absolute_sigma=True)\n",
    "\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt), zorder=10, c='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the covariance matrix\n",
    "errs = np.sqrt(pCov.diagonal()).reshape((1, -1))\n",
    "corr = pCov/(errs.T@errs)\n",
    "\n",
    "print(errs)\n",
    "\n",
    "plt.imshow(corr, vmin=-1, vmax=1, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "\n",
    "#   model(x,  B,  tau, A1, mu1, sigma1, A2, mu2, sigma2)  # Reminder of parameter order\n",
    "#             0,   1,   2,  3,    4,     5,  6,     7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot fit and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# subplot2grid is similar to subplot, but allows more customization\n",
    "# \n",
    "# subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "# First create a 3x1 grid with the following indices\n",
    "# [[0,0]\n",
    "#  [1,0]\n",
    "#  [2,0]]\n",
    "#\n",
    "# Place the current axes in cell (0, 0) and let it span 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.subplot2grid((4, 1), (0, 0), rowspan=2)\n",
    "plt.errorbar(x_data, y_data, yerr=y_err, fmt='.', capsize=3)\n",
    "plt.plot(x, model(x, *pOpt), zorder=10, c='k')\n",
    "plt.ylabel('Signal (mV)')\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "plt.tick_params(direction='in')\n",
    "\n",
    "plt.subplot2grid((4, 1), (2, 0))\n",
    "plt.stem(x_data, y_data - model(x_data, *pOpt), markerfmt='.')\n",
    "plt.tick_params(direction='in', top=True)\n",
    "plt.ylabel('Residuals (mV)')\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "plt.tick_params(direction='in')\n",
    "\n",
    "plt.subplot2grid((4, 1), (3, 0))\n",
    "plt.stem(x_data, (y_data - model(x_data, *pOpt))/y_err, markerfmt='.')\n",
    "plt.tick_params(direction='in', top=True)\n",
    "plt.ylabel('Normalized Residuals')\n",
    "plt.xlabel('t (s)')\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small or large parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
